{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781ec5c-7d77-463a-bcd0-b4b95ef7cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate evaluate trl \"tensorboard==2.15\" optuna scikit-learn --upgrade --quiet\n",
    "!huggingface-cli login --token \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51371079-c0ce-4630-a68f-ab2ec25bb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resuse https://github.com/pkasela/DESIRE-ME/blob/main/src/model/utils.py\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    logger.info(f'Setting global random seed to {seed}')\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1083f029-0fae-4ab7-88e8-5442f1ed5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27c5bf0-6813-4e21-9da8-760decf37327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline, DataCollatorWithPadding\n",
    "\n",
    "# Huggingface access token\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfFolder\n",
    "#from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "\n",
    "# Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Model performance evaluation\n",
    "import evaluate\n",
    "\n",
    "# Load to GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa82ac28-a782-42aa-ab2e-fda3c8f26473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the unbalanced binary data\n",
    "\n",
    "#train_unb = pd.read_csv('/workspace/phi3_direct_query_generation_processed_5k.csv')\n",
    "#train_unb = pd.read_csv('/workspace/phi3_topic_in_generation_5k_unique_final.csv')\n",
    "\n",
    "train_unb = pd.read_csv('/workspace/gpt4o_direction_query_generation_processed_5k_reprocessed.csv')\n",
    "#train_unb = pd.read_csv('/workspace/gpt4o_topic_in_generation_5k_unique_final.csv')\n",
    "\n",
    "#train_unb = pd.read_csv('/workspace/llama3.1_direct_generation_5k_final.csv')\n",
    "#train_unb = pd.read_csv('/workspace/llama3.1_topic_in_generation_unique_5k_final.csv')\n",
    "\n",
    "\n",
    "test_unb = pd.concat([pd.read_csv('/workspace/clariq_unbalanced/train_binary.csv'), pd.read_csv('/workspace/clariq_unbalanced/test_binary.csv'), pd.read_csv('/workspace/clariq_unbalanced/dev_binary.csv')], axis=0)\n",
    "\n",
    "train_clariq_unb = train_unb[['initial_request', 'binary_label']].drop_duplicates().dropna()\n",
    "train_clariq_unb = train_clariq_unb.reset_index(drop=True)\n",
    "#dev_clariq_unb = dev_unb[['initial_request', 'binary_label']].drop_duplicates()\n",
    "#dev_clariq_unb = dev_clariq_unb.reset_index(drop=True)\n",
    "test_clariq_unb = test_unb[['initial_request', 'binary_label']].drop_duplicates().dropna()\n",
    "test_clariq_unb = test_clariq_unb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3582899e-d84b-4b41-bce2-69c6f63dec89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_request</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the latest recommendations for managi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the benefits of incorporating mindful...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the major policy changes proposed in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the health benefits of incorporating ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are effective techniques for improving my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Is it hot?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Who’s in charge?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Turn that on.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>He took her to the zoo.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>How do I get more followers?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        initial_request  binary_label\n",
       "0     What are the latest recommendations for managi...             0\n",
       "1     What are the benefits of incorporating mindful...             0\n",
       "2     What are the major policy changes proposed in ...             0\n",
       "3     What are the health benefits of incorporating ...             0\n",
       "4     What are effective techniques for improving my...             0\n",
       "...                                                 ...           ...\n",
       "4995                                         Is it hot?             1\n",
       "4996                                   Who’s in charge?             1\n",
       "4997                                      Turn that on.             1\n",
       "4998                            He took her to the zoo.             1\n",
       "4999                       How do I get more followers?             1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clariq_unb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb2a4c-fa74-45da-bf32-af796808607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clariq_unb['label'] = train_clariq_unb['binary_label'].astype(int)\n",
    "#dev_clariq_unb['label'] = dev_clariq_unb['binary_label'].astype(int)\n",
    "test_clariq_unb['label'] = test_clariq_unb['binary_label'].astype(int)\n",
    "\n",
    "\n",
    "# Convert dataframe to Hugging Face arrow dataset\n",
    "hg_train_data = Dataset.from_pandas(train_clariq_unb[['initial_request', 'label']])\n",
    "#hg_dev_data = Dataset.from_pandas(dev_clariq_unb[['initial_request', 'label']])\n",
    "hg_test_data = Dataset.from_pandas(test_clariq_unb[['initial_request', 'label']])\n",
    "\n",
    "print(\"Length of hg_train_data\", len(hg_train_data))\n",
    "#print(\"Length of hg_dev_data\", len(hg_dev_data))\n",
    "print(\"Length of hg_test_data\", len(hg_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a069f-805c-4de3-aafa-66715708be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig_test = pd.read_csv('/workspace/ambig_test.csv')\n",
    "ambig_test = ambig_test[['question', 'label']]\n",
    "ambig_test = ambig_test.rename(columns = {'question': 'initial_request'})\n",
    "hg_ambig_test_data = Dataset.from_pandas(ambig_test)\n",
    "hg_ambig_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ea52e-8b34-4eca-bd3c-e2b2b8d0d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inscit_test = pd.read_csv('/workspace/INSCIT_test_furtherprocessed.csv')\n",
    "inscit_test = inscit_test[['initial_request', 'binary_label']]\n",
    "inscit_test = inscit_test.rename(columns = {'binary_label': 'label'})\n",
    "hg_inscit_test_data = Dataset.from_pandas(inscit_test)\n",
    "hg_inscit_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5db59d-cd39-49ef-9d48-85181d4634de",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_clariq_unb[test_clariq_unb['label']==1])/len(test_clariq_unb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b4ca6-fd3b-4bd8-b92c-19e3346b3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ambig_test[ambig_test['label']==1])/len(ambig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d1884-e3b7-44f5-8dfa-0e67dba3ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inscit_test[inscit_test['label']==1])/len(inscit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20f577-8dc1-445a-b98c-91302f0f9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer from a pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  #\"distilbert-base-uncased\"  \"bert-base-uncased\"roberta-base\n",
    "# Funtion to tokenize data\n",
    "def tokenize_dataset(data):\n",
    "    return tokenizer(data['initial_request'],\n",
    "                     max_length=512,\n",
    "                     truncation=True)\n",
    "                     #padding=\"max_length\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "dataset_train = hg_train_data.map(tokenize_dataset, batched=True)\n",
    "#dataset_dev = hg_dev_data.map(tokenize_dataset, batched=True)\n",
    "dataset_test = hg_test_data.map(tokenize_dataset, batched=True)\n",
    "dataset_test_ambig = hg_ambig_test_data.map(tokenize_dataset, batched=True)\n",
    "dataset_test_inscit = hg_inscit_test_data.map(tokenize_dataset, batched=True)\n",
    "\n",
    "\n",
    "# Dynamically pad\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# Load model\n",
    "\n",
    "#def model_init():\n",
    "  #model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=4)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2, return_dict=True).to(device) #\"bert-base-uncased\" \"distilbert-base-uncased\"roberta-base \n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    f\"...\",\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=64,\n",
    "    #per_device_eval_batch_size=64,\n",
    "    learning_rate=5e-5,\n",
    "    #weight_decay=0.01,\n",
    "    seed=42,\n",
    "\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    #eval_dataset=dataset_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fd2c2-f75d-4674-b161-5fd222422691",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660620d-29f9-4c16-9687-1772a8108168",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(trainer.predict(dataset_test).predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac59b99-d5ed-4db2-86a8-1cbf89082fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b27fef46-b41c-472c-9ac4-554a9d2c7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def compute_metrics(predictions, labels):\n",
    "\n",
    "    p= evaluate.load(\"precision\")\n",
    "    r = evaluate.load(\"recall\")\n",
    "    f = evaluate.load(\"f1\")\n",
    "    acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    bacc = balanced_accuracy_score(y_true=labels, y_pred=predictions)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = p.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    recall = r.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
    "    f1_weighted = f.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    f1_macro = f.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"] \n",
    "\n",
    "    return {\n",
    "        'bacc': bacc,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_marco': f1_macro\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a8fad-d2a0-4a9e-b97f-24b69099210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(np.argmax(trainer.predict(dataset_test).predictions, axis=1), test_clariq_unb['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c3cae-9766-4b18-94b5-bc83d9992080",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(np.argmax(trainer.predict(dataset_test_ambig).predictions, axis=1), ambig_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a31ad-c47a-4291-9921-d3d5aca20130",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(np.argmax(trainer.predict(dataset_test_inscit).predictions, axis=1), inscit_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6e857-6f00-4084-a969-accc49c06e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ce9ce-630f-43cb-a397-0307defde68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1252fc0-ddac-4ce7-b63f-ebb1a2b320e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
